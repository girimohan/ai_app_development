
# Audio Sentiment Classifier

This project implements an **Audio Sentiment Classifier** utilizing state-of-the-art models from the **Hugging Face Transformers** library. The classifier is designed to analyze audio inputs and accurately predict the sentiment conveyed within them.

## Key Features

- **Audio Analysis:** The model processes audio files to extract features relevant to sentiment analysis.
- **Transformers Architecture:** Leveraging pre-trained transformer models, including **Wav2Vec2**, **HuBERT**, and **BERT**, the classifier benefits from advanced techniques in natural language processing and audio signal processing.
- **Customizable Training:** Users can fine-tune the model on their specific audio datasets to improve performance and adapt to various sentiment classification tasks.
- **Interactive Gradio Interface:** The project includes a user-friendly interface built with **Gradio**, allowing users to easily upload audio files and visualize sentiment predictions in real-time. This interface enhances accessibility and provides a seamless user experience.

## Getting Started

1. **Installation:** Ensure that you have the necessary libraries installed, including `transformers`, `torch`, and `librosa` for audio processing, as well as `gradio` for the interface.
2. **Data Preparation:** Prepare your audio dataset in the required format for input into the model.
3. **Model Training:** Follow the provided scripts to train the model on your dataset, adjusting parameters as needed.
4. **Inference:** Use the trained model to predict sentiments on new audio samples.
5. **Launch Gradio Interface:** Run the Gradio interface to interactively upload audio files and view sentiment predictions.

## Acknowledgments

- This project utilizes the **Hugging Face Transformers** library for leveraging cutting-edge NLP techniques.
  
